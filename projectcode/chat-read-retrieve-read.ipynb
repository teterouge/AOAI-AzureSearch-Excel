{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import QueryType\n",
    "\n",
    "# Set the environment\n",
    "AZURE_STORAGE_ACCOUNT = os.environ.get(\"AZURE_STORAGE_ACCOUNT\")\n",
    "AZURE_STORAGE_CONTAINER = os.environ.get(\"AZURE_STORAGE_CONTAINER\")\n",
    "AZURE_SEARCH_SERVICE = os.environ.get(\"AZURE_SEARCH_SERVICE\")\n",
    "AZURE_SEARCH_INDEX = os.environ.get(\"AZURE_SEARCH_INDEX\")\n",
    "AZURE_OPENAI_SERVICE = os.environ.get(\"AZURE_OPENAI_SERVICE\")\n",
    "AZURE_OPENAI_CHATGPT_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\")\n",
    "AZURE_OPENAI_CHATGPT_MODEL = os.environ.get(\"AZURE_OPENAI_CHATGPT_MODEL\")\n",
    "AZURE_OPENAI_EMB_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_EMB_DEPLOYMENT\")\n",
    "\n",
    "KB_FIELDS = [\n",
    "    \"Fields\" #all Fields separated by commas from your Cog Search Index - be sure this matches those fields\n",
    "]\n",
    "\n",
    "# Set Azure Credentials - User for local & Managed Identity for Deployment\n",
    "azure_credential = DefaultAzureCredential(exclude_shared_token_cache_credential = True)\n",
    "\n",
    "# Set OpenAI details\n",
    "openai.api_base = f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\"\n",
    "openai.api_version = \"2023-05-15\"\n",
    "\n",
    "# OpenAPI credentialing\n",
    "openai.api_type = \"azure_ad\"\n",
    "openai.api_key = azure_credential.get_token(\"https://cognitiveservices.azure.com/.default\").token\n",
    "\n",
    "# Set up clients for Cognitive Search and Storage\n",
    "search_client = SearchClient(\n",
    "    endpoint=f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\",\n",
    "    index_name=AZURE_SEARCH_INDEX,\n",
    "    credential=azure_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat roles\n",
    "SYSTEM = \"system\"\n",
    "USER = \"user\"\n",
    "ASSISTANT = \"GTI.ai\"\n",
    "\n",
    "system_message_chat_conversation = \"\"\"\n",
    "Review the Azure Demo\n",
    "\"\"\"\n",
    "chat_logs= [{\"role\" : SYSTEM, \"content\" : system_message_chat_conversation}]\n",
    "\n",
    "summary_prompt_template = \"\"\"\n",
    "Review the Azure Demo\n",
    "\n",
    "Search query:\n",
    "\"\"\"\n",
    "query_summary_conversations = [{\"role\" : SYSTEM, \"content\" : summary_prompt_template}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell multiple times updating user_input to accumulate chat history\n",
    "user_input = \"Add a query for your data here\"\n",
    "query_summary_conversations.append({\"role\": USER, \"content\": user_input })\n",
    "\n",
    "# Exclude category, to simulate scenarios where there's a set of docs you can't see\n",
    "exclude_category = None\n",
    "\n",
    "query_completion = openai.ChatCompletion.create(\n",
    "    deployment_id=AZURE_OPENAI_CHATGPT_DEPLOYMENT,\n",
    "    model=AZURE_OPENAI_CHATGPT_MODEL,\n",
    "    messages=query_summary_conversations, \n",
    "    temperature=0.7, \n",
    "    max_tokens=1024, \n",
    "    n=1)\n",
    "search = query_completion.choices[0].message.content\n",
    "\n",
    "# Use Azure OpenAI to compute an embedding for the query\n",
    "query_vector = openai.Embedding.create(engine=AZURE_OPENAI_EMB_DEPLOYMENT, input=search)[\"data\"][0][\"embedding\"]\n",
    "\n",
    "# Alternatively simply use the following if not using reranking with semantic search:\n",
    "# search_client.search(search, \n",
    "#                      top=3, \n",
    "#                      vector=query_vector if query_vector else None, \n",
    "#                      top_k=50 if query_vector else None, \n",
    "#                      vector_fields=\"embedding\" if query_vector else None)\n",
    "\n",
    "print(\"Searching:\", search)\n",
    "print(\"-------------------\")\n",
    "filter = \"category ne '{}'\".format(exclude_category.replace(\"'\", \"''\")) if exclude_category else None\n",
    "r = search_client.search(search, \n",
    "                         filter=filter,\n",
    "                         query_type=QueryType.SEMANTIC, \n",
    "                         query_language=\"en-us\", \n",
    "                         query_speller=\"lexicon\", \n",
    "                         semantic_configuration_name=\"default\", \n",
    "                         top=3,\n",
    "                         # vector=query_vector if query_vector else None, \n",
    "                         # top_k=50 if query_vector else None, \n",
    "                         # vector_fields=\"embedding\" if query_vector else None)\n",
    ")\n",
    "results = [str(doc['sheetName']) + \" - \" + str(doc['Field1']) + \": \" + str(doc['Field2'])  for doc in r] # truncated. be sure to add these to match you Index fields\n",
    "\n",
    "content = \"\\n\".join(results)\n",
    "\n",
    "user_content = user_input + \" \\nSOURCES:\\n\" + content\n",
    "\n",
    "chat_logs.append({\"role\": USER, \"content\": user_content })\n",
    "\n",
    "chat_completion = openai.ChatCompletion.create(\n",
    "    deployment_id=AZURE_OPENAI_CHATGPT_DEPLOYMENT,\n",
    "    model=AZURE_OPENAI_CHATGPT_MODEL,\n",
    "    messages=chat_logs, \n",
    "    temperature=0.7, \n",
    "    max_tokens=1024, \n",
    "    n=1)\n",
    "chat_content = chat_completion.choices[0].message.content\n",
    "'''\n",
    "reset user content to avoid sources in conversation history\n",
    "add source as a single shot in query conversation\n",
    "'''\n",
    "chat_logs[-1][\"content\"] = user_input\n",
    "chat_logs.append({\"role\":ASSISTANT, \"content\": chat_content})\n",
    "query_summary_conversations.append({\"role\":ASSISTANT, \"content\": chat_content})\n",
    "\n",
    "print(\"\\n-------------------\\n\")\n",
    "for conversation in chat_logs:\n",
    "    print(conversation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c40b9fc8dfc687e53ddb074d322e19207ef9cf3db51c580aef67976913dea803"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
